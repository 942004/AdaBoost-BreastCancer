# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12erf_6K_vL3wNdg7zvLXVeiGQWpG_gY2
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Load the dataset
data = load_breast_cancer()
X, y = data.data, data.target

# Split into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Experiment with different numbers of estimators
n_estimators_range = range(10, 201, 10)
train_accuracies = []
test_accuracies = []

for n in n_estimators_range:
    adaboost = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=n, random_state=42)
    adaboost.fit(X_train, y_train)
    train_accuracies.append(accuracy_score(y_train, adaboost.predict(X_train)))
    test_accuracies.append(accuracy_score(y_test, adaboost.predict(X_test)))

# Plot training and testing accuracy
plt.figure(figsize=(10, 6))
plt.plot(n_estimators_range, train_accuracies, label='Training Accuracy', marker='o')
plt.plot(n_estimators_range, test_accuracies, label='Testing Accuracy', marker='s')
plt.xlabel('Number of Estimators')
plt.ylabel('Accuracy')
plt.title('Training and Testing Accuracy vs. Number of Estimators')
plt.legend()
plt.show()

# Explore weighting at different iterations
adaboost = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)
adaboost.fit(X_train, y_train)

print("Estimator Weights:", adaboost.estimator_weights_[:10])

# Introduce noise to training labels
np.random.seed(42)
flip_indices = np.random.choice(len(y_train), size=int(0.1 * len(y_train)), replace=False)
y_train_noisy = np.copy(y_train)
y_train_noisy[flip_indices] = 1 - y_train_noisy[flip_indices]

# Retrain with noisy data
adaboost_noisy = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)
adaboost_noisy.fit(X_train, y_train_noisy)

y_pred_noisy = adaboost_noisy.predict(X_test)
accuracy_noisy = accuracy_score(y_test, y_pred_noisy)
print(f"Test Accuracy with Noisy Data: {accuracy_noisy:.4f}")